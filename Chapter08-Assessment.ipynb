{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/HDAT9500Banner.PNG)\n",
    "<br>\n",
    "\n",
    "# Chapter 8: Sequential Data, \n",
    "# Assessment: Build an HMM from Data (Baum-Welch algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################################\n",
    "\n",
    "Double-click to write down your name and surname.\n",
    "\n",
    "**Name:**\n",
    "Alexander\n",
    "\n",
    "**Surname:** \n",
    "Kruskal\n",
    "\n",
    "**Honour Pledge** <p>\n",
    "    \n",
    "    \n",
    "Declaration: <p>\n",
    "    \n",
    "    \n",
    "I declare that this assessment item is my own work, except where acknowledged, and has not been submitted for academic credit elsewhere or previously, or produced independently of this course (e.g. for a third party such as your place of employment) and acknowledge that the assessor of this item may, for the purpose of assessing this item: \n",
    "\n",
    "    a. Reproduce this assessment item and provide a copy to another member of the University; and/or \n",
    "    b. Communicate a copy of this assessment item to a plagiarism checking service (which may then retain a copy of the assessment item on its database for the purpose of future plagiarism checking). \n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "In the previous exercise, we built an HMM from scratch. We could do this because we knew the values of the probabilities for the model in advance. <p>\n",
    "In this case, we are going to create a model (to fit a model) using some data. But we are going to initialise the probabilies at random. Therefore, the model will be learn from data.<p>\n",
    "Again, we will use the HMM in an **unsupervised manner**.\n",
    "    \n",
    "\n",
    "## 1.1. Aims of the Exercise:\n",
    " 1. To continue working with HMMs.\n",
    " 2. To explore sequential data.\n",
    " 3. To create an HMM using Baum-Welch alrightm.\n",
    " 4. To use an HMM to work in **unsupervised** manner (**unsupervised learning**). HMM can be used in a supervised way too, but we are not going to study it in this lesson.\n",
    " \n",
    "It aligns with all the learning outcome of our course: \n",
    "\n",
    "1.\tDistinguish a range of task specific machine learning techniques appropriate for Health Data Science.\n",
    "2.\tDesign machine learning tasks for Health Data Science scenarios.\n",
    "3.\tConstruct appropriate training and test sets for health research data.\n",
    "\n",
    "\n",
    "## 1.2. Jupyter Notebook Intructions\n",
    "1. Read the content of each cell.\n",
    "2. Where necessary, follow the instructions that are written in each cell.\n",
    "3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n",
    "4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell.\n",
    " \n",
    "## 1.3. Tips\n",
    " 1. The square brackets on the left hand side of each cell indicate whether the cell has been executed or not. Empty square brackets mean that the cell has not been excuted, whereas square brackets that contain a number means that the cell has been executed. Run all the cells in sequence, using the \"Run\" button.\n",
    " 2. To edit this notebook, just double-click in each cell. In thid document, each cell can be a \"Code\" cell or \"text-Markdown\" cell. To choose between these two options, go to the combo-box above. \n",
    " 3. If you want to save your notebook, please make sure you press \"the floppy disk\" icon button above. \n",
    " 4. To clean the content of all cells and re-start Notebook, please go to Cell->All Output->Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "#For this notebook to work, Python must be 3.6.4 or 3.6.5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instructions\n",
    "1. Let's assume that we do not have the HMM that we created in the previous exercise.\n",
    "2. In this exercise, we are going to create an HMM from scratch. Let us assume that in this case, we do not know the probabilies/parameters of our HMM. You will initialize all the probabilites at random, except the probability of state \"5\" that we assume we know it: <p>\n",
    "    * model.add_transition(s2, s2, 0.00)\n",
    "    * model.add_transition(s2, s3, 1.00)<p>\n",
    "3. In contrast, we have some data that we can use to fit/infer our model. Check questions 1g and 1h of the previous exercise (you should have generated at least 20 sequences).\n",
    "4. We are going to use the function fit() for fit our model.\n",
    "        https://media.readthedocs.org/pdf/pomegranate/stable/pomegranate.pdf <p>\n",
    "        See function \"fit()\"\n",
    "5. Follow the instructions below. Each of the questions include instructions.\n",
    "6. Below is a graphical representation of what we know about our HMM. That is, this is the only certain information that we have with respect to our HMM (along with the data sequences that we are using to \"train\" our model).\n",
    "\n",
    "![alt text](images/HMM_to_train.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1. Initial Probability and transition probabily of state \"5\" to state I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Start Activity 1**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 1:  Load the data that you generated in the previous exercise (5 marks)</font> <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r sequences\n",
    "sequence = sequences[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sequence))\n",
    "print(type(sequence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pomegranate\n",
    "from pomegranate import *\n",
    "model=HiddenMarkovModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = HiddenMarkovModel('DNA Decodification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 2: Define the emission probabilities, link the emission probabilities to the states/hidden variables of your HMM and intitialize the transition probabilites. All the probabilities shoud be initialized randomly, except the ones provided above (see Figure). The states will be named \"E\", \"5\" and \"I\" as before. (40 marks). </font> \n",
    "<font color='green'>Tip: Read the pomegranate documenation, Hidden Markov Models section: https://media.readthedocs.org/pdf/pomegranate/latest/pomegranate.pdf </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_DNA_probabilities(seedx):\n",
    "    '''\n",
    "    input: seed - random seed\n",
    "    output: dictionary of descrete probabilities like - {A: .5, C: 0, G: .5, T: 0} summing to 1\n",
    "\n",
    "    Generates 4 probabilites adding up to 1 by randomly selecting a value between 0 and remaining percentage.\n",
    "    Shuffles those probabilites so that it is random to which coding the probability is assigned.\n",
    "    '''\n",
    "\n",
    "    from random import seed\n",
    "    from random import randint\n",
    "    from random import shuffle\n",
    "    \n",
    "    seed(seedx) # seed random number generator\n",
    "\n",
    "    dict_discrete_dist = {} #output dict\n",
    "    DNA_probabilities =[] #list probabilities\n",
    "    DNA_codings = ['A', 'C', 'G', 'T'] #list Coding names\n",
    "    percent_left = 100 #percent left through each iteration\n",
    "    \n",
    "    #create 4 probabilites summing to 100\n",
    "    for i in DNA_codings:\n",
    "        temp_percent = randint(0, percent_left)\n",
    "        temp_decimal = temp_percent/100 #make decimal\n",
    "        DNA_probabilities.append(temp_decimal)\n",
    "        percent_left = percent_left - temp_percent\n",
    "    DNA_probabilities[3] = DNA_probabilities[3] + (percent_left/100) #add remaining probability to last one\n",
    "    \n",
    "    #round to avoid floating error\n",
    "    rounder = lambda x: round(x, 2)\n",
    "    DNA_probabilities = [rounder(i) for i in DNA_probabilities]\n",
    "    shuffle(DNA_probabilities)\n",
    "\n",
    "    #make dictionary\n",
    "    dict_discrete_dist = dict(zip(DNA_codings, DNA_probabilities))\n",
    "    return(dict_discrete_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transition_probabilities(seedx):\n",
    "    '''\n",
    "    input: seed - random seed\n",
    "    output: list pair of numbers summing to 1\n",
    "    \n",
    "    '''\n",
    "\n",
    "    from random import seed\n",
    "    from random import randint\n",
    "    from random import shuffle\n",
    "    \n",
    "    seed(seedx) # seed random number generator\n",
    "    \n",
    "    #first and remaining percentage\n",
    "    percent1 = randint(0, 100)\n",
    "    percent2 = 100 - percent1\n",
    "    \n",
    "    #make list and shuffle\n",
    "    decimal_probs = [percent1, percent2]\n",
    "    shuffle(decimal_probs)\n",
    "    \n",
    "    #devide by 100 and round to avoid floating error\n",
    "    rounder = lambda x: round(x, 2)\n",
    "    decimal_probs = [rounder(i/100) for i in decimal_probs]\n",
    "    \n",
    "    return(decimal_probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dE = DiscreteDistribution(random_DNA_probabilities(10))\n",
    "d5 = DiscreteDistribution(random_DNA_probabilities(27))\n",
    "dI = DiscreteDistribution(random_DNA_probabilities(1094))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = State(dE, name=\"E\")\n",
    "s2 = State(d5, name=\"5\")\n",
    "s3 = State(dI, name=\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_states(s1, s2, s3)\n",
    "model.add_transition(model.start, s1, 1.0)\n",
    "model.add_transition(s1, s1, random_transition_probabilities(1743)[0])\n",
    "model.add_transition(s1, s2, random_transition_probabilities(1743)[1])\n",
    "model.add_transition(s2, s2, 0.0)\n",
    "model.add_transition(s2, s3, 1.0)\n",
    "model.add_transition(s3, s3, random_transition_probabilities(74)[0])\n",
    "model.add_transition(s3,model.end, random_transition_probabilities(74)[1])\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 3: Once you have initilized our HMM with random values, let's fit the model with our data (sequences) in order to \"train\" the model and find good parameteres. Give an argument of stop_threshold=0.01 (10 marks). </font> <p>\n",
    "<font color='green'> Tip: Function \"fit()\" in the pomegranate documenation, Hidden Markov Models section: \n",
    "https://media.readthedocs.org/pdf/pomegranate/stable/pomegranate.pdf <p>\n",
    "         </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"class\" : \"HiddenMarkovModel\",\n",
       "    \"name\" : \"None\",\n",
       "    \"start\" : {\n",
       "        \"class\" : \"State\",\n",
       "        \"distribution\" : null,\n",
       "        \"name\" : \"None-start\",\n",
       "        \"weight\" : 1.0\n",
       "    },\n",
       "    \"end\" : {\n",
       "        \"class\" : \"State\",\n",
       "        \"distribution\" : null,\n",
       "        \"name\" : \"None-end\",\n",
       "        \"weight\" : 1.0\n",
       "    },\n",
       "    \"states\" : [\n",
       "        {\n",
       "            \"class\" : \"State\",\n",
       "            \"distribution\" : {\n",
       "                \"class\" : \"Distribution\",\n",
       "                \"dtype\" : \"str\",\n",
       "                \"name\" : \"DiscreteDistribution\",\n",
       "                \"parameters\" : [\n",
       "                    {\n",
       "                        \"A\" : 0.00023678279903128197,\n",
       "                        \"C\" : 0.0,\n",
       "                        \"G\" : 0.9707011321207472,\n",
       "                        \"T\" : 0.029062085080221508\n",
       "                    }\n",
       "                ],\n",
       "                \"frozen\" : false\n",
       "            },\n",
       "            \"name\" : \"5\",\n",
       "            \"weight\" : 1.0\n",
       "        },\n",
       "        {\n",
       "            \"class\" : \"State\",\n",
       "            \"distribution\" : {\n",
       "                \"class\" : \"Distribution\",\n",
       "                \"dtype\" : \"str\",\n",
       "                \"name\" : \"DiscreteDistribution\",\n",
       "                \"parameters\" : [\n",
       "                    {\n",
       "                        \"A\" : 0.30578111968596805,\n",
       "                        \"C\" : 0.2467769102879259,\n",
       "                        \"G\" : 0.2139476589856386,\n",
       "                        \"T\" : 0.23349431104046758\n",
       "                    }\n",
       "                ],\n",
       "                \"frozen\" : false\n",
       "            },\n",
       "            \"name\" : \"E\",\n",
       "            \"weight\" : 1.0\n",
       "        },\n",
       "        {\n",
       "            \"class\" : \"State\",\n",
       "            \"distribution\" : {\n",
       "                \"class\" : \"Distribution\",\n",
       "                \"dtype\" : \"str\",\n",
       "                \"name\" : \"DiscreteDistribution\",\n",
       "                \"parameters\" : [\n",
       "                    {\n",
       "                        \"A\" : 0.405577466441345,\n",
       "                        \"C\" : 0.12260028962976643,\n",
       "                        \"G\" : 0.09268287228335394,\n",
       "                        \"T\" : 0.3791393716455343\n",
       "                    }\n",
       "                ],\n",
       "                \"frozen\" : false\n",
       "            },\n",
       "            \"name\" : \"I\",\n",
       "            \"weight\" : 1.0\n",
       "        },\n",
       "        {\n",
       "            \"class\" : \"State\",\n",
       "            \"distribution\" : null,\n",
       "            \"name\" : \"None-start\",\n",
       "            \"weight\" : 1.0\n",
       "        },\n",
       "        {\n",
       "            \"class\" : \"State\",\n",
       "            \"distribution\" : null,\n",
       "            \"name\" : \"None-end\",\n",
       "            \"weight\" : 1.0\n",
       "        }\n",
       "    ],\n",
       "    \"end_index\" : 4,\n",
       "    \"start_index\" : 3,\n",
       "    \"silent_index\" : 3,\n",
       "    \"edges\" : [\n",
       "        [\n",
       "            3,\n",
       "            1,\n",
       "            1.0,\n",
       "            1.0,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            1,\n",
       "            1,\n",
       "            0.8879235717703614,\n",
       "            0.16,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            1,\n",
       "            0,\n",
       "            0.11207642822963855,\n",
       "            0.84,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            0,\n",
       "            0,\n",
       "            0.0,\n",
       "            0.0,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            0,\n",
       "            2,\n",
       "            1.0,\n",
       "            1.0,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            2,\n",
       "            2,\n",
       "            0.920807868884625,\n",
       "            0.22,\n",
       "            null\n",
       "        ],\n",
       "        [\n",
       "            2,\n",
       "            4,\n",
       "            0.079192131115375,\n",
       "            0.78,\n",
       "            null\n",
       "        ]\n",
       "    ],\n",
       "    \"distribution ties\" : []\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequence, stop_threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 4: Use the DNA sequence test that we used in the previous exercise and check that you obtain the same result (or very similar) as before. (20 marks) </font> <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_test= list('CTTCATGTGAAAGCAGACGTAAGTCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None-start-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-5-I-I-I-I-I-I-I-None-end\n"
     ]
    }
   ],
   "source": [
    "print(\"-\".join(state.name for i, state in model.viterbi(DNA_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability: -40.23\n",
      "This is similar to the model in the exercise, being -40.55 log-probability\n"
     ]
    }
   ],
   "source": [
    "print('Log probability: {:.2f}'.format(model.log_probability(DNA_test)))\n",
    "print('This is similar to the model in the exercise, being -40.55 log-probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 3.3808283104923828e-18\n",
      "This is similar to the model in the exercise, being 2.72*10^-18% probability\n"
     ]
    }
   ],
   "source": [
    "print('Probability: {}'.format(np.exp(model.log_probability(DNA_test))))\n",
    "print('This is similar to the model in the exercise, being 2.72*10^-18% probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 5: With all this knowledge, give a definition of what an HMM is, when you can use it and how you can use it. Minimum 200 words-Maximum 600 words approximately (10 marks). </font> <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Hidden Markov Model is a model that uses observable data to predict hidden or unkown information. For example, with the DNA sequencing, we know the actual DNA sequences, but we do not know which of the three states any coding in the sequence is in. With the observed data and knowing that there are 3 states, the Hidden Markove Model can predict the state and transition probablilites to use the known observation of the codings to determine the unkown states of each DNA coding in the sequence.  \n",
    "In another real world example, you might observe the weather, the time of year, and the day of the week to determine how busy a bakery might be. In that example the known observations are the weather,time of year, and day of the week. With that information, you might be able to predict the hidden information - how many muffins you are likely to sell. That would then empower the business to either bake more or fewer muffins in the morning to avoid waste or potenetial loss from not having enough to sell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Question 6: Which task or tasks, of those explained in section 4 in the previous exercise, did we carry out here? Give the task(s) and explain how they are used here. (15 marks)</font> <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the tasks explained in section 4, we did all three tasks.  \n",
    "Task 1 is learning or training the model. We did this when we fit the model to our randomly initialised model to our list of sequences.  \n",
    "Task 2 is finding the probability of an observed sequence given the model. We did this by taking the log probability in question 4 to see if it has a simialer log probability to the model that generated the sequences for the test DNA sequence.  \n",
    "Task 3 is done using the viterbi function printing out the hidden states for the test DNA sequence to make sure it is similar to the expected hidden states for the DNA test sequence. My model has state '5' 8th from the end instead of 7th from the end, but also the probabilites for the DNA encoding (A, C, G, T) for each state has probabilities closely resembling that of the model the sequences were generated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
